\documentclass[../main.tex]
		
		\begin{document}
			\section{Regular Grammars}
	\begin{description}
		\item[Task:] Understand what is the form of the production rules of a grammar that generates a regular language.
		\item[Recall] that a context-free grammar is given by $(V, A, \langle s\rangle , P)$ where every production rule $\langle T\rangle  \rightarrow w$ in $P$ causes \underline{one and only one} nonterminal to be replaced by a string in $V^*$.
		\item[Definition:] A context-free grammar $(V, A, \langle s\rangle , P)$ is called a \underline{regular grammar} is every production rule in $P$ is of one of the three forms:
		\begin{enumerate}
			\item[(i)] $\langle A\rangle  \rightarrow$ b$\langle B\rangle $
			\item[(ii)] $\langle A\rangle  \rightarrow$ b
			\item[(iii)] $\langle A\rangle  \rightarrow \varepsilon$
		\end{enumerate}
		where $\langle A\rangle $ and $\langle B\rangle $ are nonterminals, $b$ is a terminal, and $\varepsilon$ is the empty word. A regular grammar is said to be in normal form if all its production rules are of types (i) and (iii).
		\item[Remark:] In the literature, you often see this definition labelled \underline{left-regular grammar} as opposed to \underline{right-regular grammar}, where the production rules of types 1 have the form $\langle A\rangle  \rightarrow \langle B\rangle $b, (\textbf{i.e.} the terminal is one the right of the nonterminal). This distinction is not really important as long as we stick to one type throughout since both \underline{left regular grammars} and \underline{right regular grammars} generate regular languages.
		\item[Lemma:] Any language generated by a regular grammar may be generated by a regular grammar in normal form.
		\item[Proof:] Let $\langle A\rangle  \rightarrow$b be a rule of type (ii). Replace it by two rules: $\langle A\rangle  \rightarrow$b$\langle F\rangle $ and $\langle F\rangle  \rightarrow \varepsilon$, where $\langle F\rangle $ s a new nonterminal. Add $\langle F\rangle $ to the set $V$. We do the same for every rule of type (ii) obtaining a bigger set $V$, but now our production rules are only of type (i) and (iii) and we are generating the same language.
		\item[qed]
		\item[Example:] Recall the regular language $L = \{0^m1^n \mid m, n \in \mathbb{N}, m \geq 0, n \geq 0 \}$. We can generate it from the regular grammar in normal gorm given by production rules:
		\begin{enumerate}
			\item $\langle s\rangle  \rightarrow 0\langle A\rangle $
			\item $\langle A\rangle  \rightarrow 0\langle A\rangle $
			\item $\langle A\rangle  \rightarrow \varepsilon$
			\item $\langle s\rangle  \rightarrow \varepsilon$
			\item $\langle A\rangle  \rightarrow 1\langle B\rangle $
			\item $\langle B\rangle  \rightarrow 1\langle B\rangle $
			\item $\langle s\rangle  \rightarrow 1\langle B\rangle $
			\item $\langle B\rangle  \rightarrow \varepsilon$
		\end{enumerate}
		Rules (1), (2), (5), (6), (7) are of type (i), where rules (3), (4) and (8) are of types (iii). \\
		(1) and (3) gives 0. (1), (2) applied $m-1$ times and (3) gives $0^m$ for $m \geq 2$. \\
		(7) and (8) give 1. (7), (6) applied $n-1$ times and (8) give $1^n$ for $n \geq 2$. \\
		(1), (5) and (8) give 01. (1), (5), (6) applied $n-1$ times and (8) gives $01^n$ for $n \geq 2$. \\
		(1), (2) applied $m-1$ times, (5) and (8) gives $0^m1$ for $m \geq 2$. \\
		(1), (2) applied $m-1$ times, (5), (6) applied $n-1$ times, and (8) gives $0^m1^n$ for $m \geq 2, n \geq 2$. \\
		Rule (4) gives the empty word $\varepsilon = 0^01^0$.
		\item[Q:] Why does a regular grammar yield a regular language, \textbf{i.e.} one recognised by a finite state acceptor?
		\item[A:] Not obvious from the definition, \underline{but} we can construct the finite state acceptor from the regular grammar as follows: our regular grammar is given by $(V, A, \langle s\rangle , P)$.  \underline{Want} a finite state acceptor $(S, A, i, t, F)$. Immediately, we see the alphabet $A$ is the same and $i=\langle s\rangle $. This gives us the idea of associating to every nonterminal symbol in $B \backslash A$ a state. $\langle s\rangle  \in V \backslash A$, so that's good. Next we ask:
		\item[Q:] Is it sufficient for $S = V \backslash A$?
		\item[A:] No! Our set $F$ of finishing/accepting states should be nonempty. So we add an element $\{f\}$ to $V \backslash A$, where our acceptor will end up when a word in our language. Thus, $S = (V \backslash A) \cup \{f\}$ and $F \{f\}$. $F \subseteq S$ as needed.
		\item[Q:] How do we define $t$?
		\item[A:] Use the production rules in $P$! For every rule of type (i), which is of the form $\langle A\rangle  \rightarrow$ b$\langle B\rangle $ set $t(\langle A\rangle $,b$) = \langle B\rangle $. This works out well because our nonterminals $\langle A\rangle $ and $\langle B\rangle $ are states of the acceptor and the terminal $b \in A$ for $t$ takes an element of $S \times A$ to an element of $S$ as needed. Now look at production rules of type (ii), $\langle A\rangle  \rightarrow b$ and of types (iii), $\langle A\rangle  \rightarrow \varepsilon$. Those are applied when we \underline{finish} constructing a word $w$ in our language $L$, \textbf{i.e.} at the very last step, so our acceptor should end up in the finishing state $f$ whenever a production rule of type (ii) or (iii) is applied. Write a production rule of type (ii) or (iii) as $\langle A\rangle  \rightarrow w$, then we can set $t(\langle A\rangle , w) = f$. We have finished constructing $t$ as well. Technically, $t:S \times (A \cup \{ \varepsilon \}) \rightarrow S$ instead of $t:S \times A \rightarrow S$, but we can easily fix the transition function t by combining the last two transitions for each accepted word.
		\item[Remark:] The same general principals as we used above allow us to go from a finite state acceptor to a regular grammar. This gives us the following theorem:
		\item[Theorem:] A language $L$ is regular $\Leftrightarrow L$ is recognised by a finite state acceptor $\Leftrightarrow L$ is generated by a regular grammar.
	\end{description}
	
	\subsection{Applications of Formal Languages and Grammars as well as Automata Theory}
	\begin{enumerate}
		\item Compiler architecture uses context-free grammars
		\item Parsers - recognise if commands comply with the syntax of a language
		\item Pattern matching and data mining - guess the language from a given set of words (applied in CS, etc)
		\item Natural language processing - example in David Wilkins' notes pp40-44
		\item Checking proofs by computers/automatic theorem proving - simpler example of this kind in David Wilkins' notes pp45-57 that pertains to propositional logic
		\item Theory of regular expressions (related to the definition of a regular language that we gave) enables
		\begin{enumerate}
			\item grep/awk/sed in Unix
			\item More efficient coding (avoiding unnecessary detoirs in your code)
		\end{enumerate}
		\item Biology - John Conway's game of life is a cellular automation
		\item Modelling of AI characters in games uses the finite state automation idea. Our character can choose among different behaviours based on stimuli - like a finite state automation reacting to input
		\item Strategy and tactics in games - teach the opposition to recognise certain patterns, then suddenly change them to gain an advantage and score - used in football, fencing, etc.
		\item Learning a sport/a numerical instrument/a new field or subject - split the information into blocks and learn how to combine them into meaningful patterns - uses notions from context-sensitive grammars.
		\item Finite state automata and probability - chaos theory, financial mathematics.
		\item[etc\dots]
	\end{enumerate}
	

\end{document}