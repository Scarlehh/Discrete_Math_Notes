\documentclass[../main.tex]
		
		\begin{document}
			\begin{description}
		\item[Task:] Use what we learned about structures in abstract algebra in order to make sense of formal languages and grammars. \\
		Let $A$ be a finite set. When studying formal languages, we call $A$ an \underline{alphabet} and the elements of $A$ \underline{letters}.
		\item[Examples:]
		\begin{enumerate}
			\item[]
			\item $A = \{0, 1\}$ \hspace{10mm} binary digits
			\item $A = \{0, 1, 2, 3, 4, 5, 6, 7, 8, 9\}$ \hspace{10mm} decimal digits
			\item $A =$ {letters of the English alphabet}
		\end{enumerate}
		\item[Definition:] $\forall n \in \mathbb{N}^*$, we define a \underline{word} of length $n$ in the alphabet $A$ as being any string of the form $a_1, a_2, \dots, a_n \: s.t. \: a_i \in A \hspace{5mm} \forall i, 1 \leq i \leq n$. Let $A^n$ be the set of all words of length $n$ over the alphabet $A$.
		\item[Remark:] There is a one-to-one correspondence between the string $a_1a_2\dots a_n$ and the ordered n-tuple $(a_1, a_2, \dots, a_n) \in A^n = \underset{n \: times}{\underbrace{A \times \dots \times A}}$ the Cartesian product of $n$ copies of $A$.
		\item[Definition:] Let $A^+ = \underset{n=1}{\overset{\infty}{\cup}} A^n = A^1 \cup A^2 \cup A^3 \cup \dots$. $A^+$ is the set of all words of positive length over the alphabet $A$.
		\item[Examples:]
		\begin{enumerate}
			\item[]
			\item $A = \{0, 1\}, A^+$ is the set of all binary strings of finite length that is at least on, \textbf{i.e.} $0, 1, 01, 10, 00, 11,$ etc.
			\item If $A =$ {letters of the English alphabet}, then $A^+$ consists of all non-empty strings of finite lengths of letters from the English alphabet. \\
			It is useful to also have the empty for $\varepsilon$ in our set of strings. $\varepsilon$ has length 0. Define $A^0 = \{\varepsilon\}$ and then adjoin the empty word $\varepsilon$ to $A^+$. We get $A^* = \{\varepsilon\} \cup A^+ = A^0 \cup \underset{n=1}{\overset{\infty}{\cup}} A^n = \underset{n=0}{\overset{\infty}{\cup}} A^n$.
		\end{enumerate}
		\item[Notation:] We denote the length of a word $w$ by $\mid w\mid$. Next introduce an operation on $A^*$.
		\item[Definition:] Let $A$ be a finite set and let $w_1 \land w_2$ be words in $A^*$. $w_1 = a_1a_2\dots a_m \land w_2 = b_1b_2\dots b_n$. The \underline{concatenation} of $w_1 \land w_2$ is the word $w_1 \circ w_2$, where $w_1 \circ w_2 = a_1a_2\dots a_mb_1b_2\dots b_n$. Sometimes $w_1 \circ w_2$ is denoted as just $w_1w_2$. Note that $\mid w_1 \circ w_2 \mid = \mid w_1 \mid + \mid w_2 \mid$. \\
		Concatenation of words is:
		\begin{enumerate}
			\item associative
			\item \underline{NOT} commutative is $A$ has more than one element.
		\end{enumerate}
		\begin{description}
			\item[Proof of (1):] Let $w_1, w_2, w_3 \in A^*. w_1 = a_1a_2\dots a_m$ for some $m \in \mathbb{N}, w_2=b_1b_2\dots b_n$ for some $m \in \mathbb{N}$ and $w_3 = c_1c_2\dots c_p$ for some $p \in \mathbb{N}$. $w_1 \circ w_2) \circ w_3 = w_1 \circ (w_2 \circ w_3) = a_1a_2\dots a_mb_1b_2\dots b_nc_1c_2\dots c_p$.
			\item[qed]
			\item[Proof of (2):] Since $A$ has at least two elements, $\exists a, b \in A$ s.t. $a \neq b$.
			\item $a \circ b = ab \neq ba = b \circ a$.
			\item[qed]
		\end{description}
		\item $A^*$ is closed under the operation of concatenation $\Rightarrow$ concatenation is a binary operation of $A^*$ as $\forall w_1, w_2 \in A^*, w_1 \circ w_2 \in A^*$.
		\item[Theorem] Let $A$ be a finite set. $(A^*, \circ)$ is a monoid with identity element $\varepsilon$.
		\item[Proof:] Concatenation $\circ$ is an associative binary operation on $A^*$ as we showed above. Moreover, $\forall w \in A^*, \varepsilon \circ w = w \circ \varepsilon = w$, so $\varepsilon$ is the identity element of $A^*$.
		\item[qed]
		\item[Definition:] Let $A$ be a finite set. A \underline{language} over $A$ is a subset of $A^*$. A language $L$ over $A$ is called a \underline{formal language} if $\exists$ a finite set of rules of algorithm that generates exactly $L$, \textbf{i.e.} all words that belong to $L$ and no other words.
		\item[Theorem:] Let $A$ be a finite set.
		\begin{enumerate}
			\item If $L_1$ and $L_2$ are languages over $A, L_1 \cup L_2$ is a language over $A$.
			\item If $L_1$ and $L_2$ are languages over $A, L_1 \cap L_2$ is a language over $A$.
			\item If $L_1$ and $L_2$ are languages over $A$, the concatenation of $L_1 \land L_2$ given by $L_1 \circ L_2 = \{w_1 \circ w_2 \in A^* \mid w_1 \in L_1 \land w_2 \in L_2\}$ is a language over $A$.
			\item Let $L$ be a language over $A$. Define $L^1=L$ inductively for and $n\geq 1 \hspace{5mm} L^n = L \circ L^{n-1}$. $L^n$ is a language over $A$. Furthermore, $L^* = \{\varepsilon\} \cup L^1 \cup L^2 \cup L^3 \cup \dots = \underset{n=0}{\overset{\infty}{\cup}} L^n$ is a language over $A$.
		\end{enumerate}
		\item[Proof:] By definition, a language over $A$ is a subset of $A^*$. Therefore, if $L_1 \subseteq A^* \land L_2 \subseteq A^*$, then $L_1 \cup L_2 \subseteq A^* \land L_1 \cap L_2 \subseteq A^*$. $\forall w_1 \circ w_2 \in L_1 \circ L_2, w_1 \circ w_2 \in A^*$ becomes $w_1 \in A^n$ for some $n$ and $w_2 \in A^m$ for some $m$ so $w_1 \circ w_2 \in A^{m+n} \subseteq A^* = \underset{n=1}{\overset{\infty}{\cup}} A^n$.
		\item Applying the same reasoning inductively, we see that $L \subset A^* \Rightarrow L^* \subseteq A^*$ as $L^m \subseteq A^* \: \forall n \geq 0$.
		\item[qed]
		\item[Remark:] This theorem gives us a theoretic way of building languages, but we need a practical way. The practical way of building a language is through the notion of a grammar.
		\item[Definition:] A (formal) grammar is a set of production rules for strings in a language. \\
		To generate a language we use:
		\begin{enumerate}
			\item $A$ the set, which is the alphabet of the language.
			\item A start symbol $\langle s\rangle $
			\item A set of production rules.
		\end{enumerate}
		\item[Example:] $A = \{0, 1\}$; start symbol $\langle s\rangle $; 2 production rules given by:
		\begin{enumerate}
			\item $\langle s\rangle $ $\rightarrow$ 0$\langle s\rangle $1
			\item $\langle s\rangle $ $\rightarrow$ 01
		\end{enumerate}
		Let's see what we generate: via rule 2 \hspace{5mm} $\langle s\rangle $ $\rightarrow$ 01, so we get $\langle s\rangle $ $\Rightarrow$ 01 \\
		Via rule 1 \hspace{5mm} $\langle s\rangle $ $\rightarrow$ 0$\langle s\rangle $1, then via rule 2, 0$\langle s\rangle $1 $\rightarrow$ 0011. We write the process as $\langle s\rangle $ $\rightarrow$ 0$\langle s\rangle $1 $\Rightarrow$ 0011. \\
		Via rule 1, $\langle s\rangle $ $\rightarrow$ 0$\langle s\rangle $1, then via rule 1 again 0$\langle s\rangle $1 $\rightarrow$ 00$\langle s\rangle $11, then via rule 2, 00$\langle s\rangle $11 $\rightarrow$ 000111. \\
		We got $\langle s\rangle $ $\Rightarrow$ 0$\langle s\rangle $1 $\Rightarrow$ 00$\langle s\rangle $11 $\Rightarrow$ 000111. \\
		The language $L$ we generated thus consists of all strings of the form $0^m1^m$ ($m$ 0's followed by $m$ 1's) for all $m \geq 1, m \in \mathbb{N}$ \\
		We saw 2 types of strings that appeared in this process of generating $L$:
		\begin{enumerate}
			\item \underline{terminals}, \textbf{i.e.} the elements of $A$
			\item \underline{nonterminals}, \textbf{i.e.} strings that don't consist solely of 0's and 1's such as $\langle s\rangle $, 0$\langle s\rangle $1, 00$\langle s\rangle $11, etc.
		\end{enumerate}
		The production rules then have the form:
		\begin{description}
			\item nonterminal $\rightarrow$ word over the alphabet V = {terminals, non-terminals}
			\item $\langle T\rangle $ $\rightarrow$ w
		\end{description}
		In our notation, the set of nonterminals if $V \backslash A$, so $\langle T\rangle \in V \backslash A \land w \in V^* = \underset{n=0}{\overset{\infty}{\cup}} V^n$. To the production rule $\langle T\rangle \rightarrow w$. \\
		We can associate the ordered pair ($\langle T\rangle , w) \in (V \backslash A) \times V^*$, so the set of production rules, which we will denote by $P$, is a subset of the Cartesian product $(V\backslash A) \times V^*$. \\
		Grammers come in two flavours:
		\begin{enumerate}
			\item \underline{Context-free grammars} where we can replace \underline{any} occurrence of $\langle T\rangle $ by $w$ if $\langle T\rangle \rightarrow w$ is one of our production rules.
			\item \underline{Context-sensitive grammars} only certain replacements of $\langle T\rangle $ by $w$ are allowed, which are governed by the syntax of our language $L$.
		\end{enumerate}
		The example we have was of a context free grammar. We can now finally define context free grammars.
		\item[Definition:] A \underline{context free grammar} $(V, A, \langle s\rangle, P)$ consists of a finite set $V$, a subset $A$ of $V$, an element $\langle s \rangle$ of $V \backslash A$, and a finite subset $P$ of the Cartesian product $V\backslash A \times V^*$.
		\item[Notation:] $(\underset{set\:of\:terminals\:and\:non\:terminals}{V}$, $\underset{set\:of\:terminals}{A}$, $\underset{start\:symbol}{\langle s\rangle }$, $\underset{set\:of\:production\:rules}{P})$
		\item[Example:] $A = \{0, 1\}$; start symbol $\langle s\rangle $; 3 production rules given by:
		\begin{enumerate}
			\item $\langle s\rangle \rightarrow 0 \langle s \rangle 1$
			\item $\langle s\rangle \rightarrow 01 $
			\item $\langle s\rangle \rightarrow 0011$
		\end{enumerate}
		We notice here that the word 0011 can be generated in 2 ways in this context free grammar:
		\begin{enumerate}
			\item[By rule 3,] $\langle s\rangle \rightarrow$ 0011 so $\langle s\rangle \Rightarrow$ 0011
			\item[] $\lor$
			\item[By rule 1,] $\langle s\rangle \rightarrow$ 0$\langle s\rangle $1 and by rule 2, 0$\langle s\rangle $1 $\rightarrow$ 0011. Therefore, $\langle s\rangle \Rightarrow$ 0$\langle s\rangle 1 \Rightarrow 0011$.
		\end{enumerate}
		\item[Definition:] A grammar is called \underline{ambiguous} if it generates the same string in more than one way. \\
		Obviously, we prefer to have unambiguous grammars, else we waste computer operations. \\
		Next, we need to spell out how words \underline{relate} to each other in the production of our language via the grammar:
		\item[Definition:] Let $w'$ and $w''$ be words over the alphabet $V$ = {terminals, non-terminals}. We say that \underline{$w'$ directly yields $w''$} if $\exists$ words $u \land v$ over the alphabet $V$ and a production rule $\langle T\rangle \rightarrow w$ of the grammar s.t. $w' = u\langle T\rangle \land w'' = uwv$, where either or both of the words $u$ and $v$ may be the empty word. \\
		In other words, $w'$ directly yields $w'' \Leftrightarrow \exists$ production rule $\langle T\rangle \rightarrow w$ in the grammar s.t. $w''$ may be obtained from $w'$ by replacing a simple occurrence of the nonterminal $\langle T\rangle $ within the word $w'$ by the word $w$.
		\item[Notation:] $w'$ directly yields $w''$ is denoted by $w' \Rightarrow w''$
		\item[Definition:] Let $w' \land w''$ be words over the alphabet $V$. We say that $w'$ yields $w''$ if either $w'= w''$ or else $\exists$ words $w_0, w_1, \dots w_n$ over the alphabet $V$ s.t. $w_0=w', w_n = w'', w_{i-1} \Rightarrow w_i$ for all $i, 1 \leq i \leq n$. In other words, $w_0 \Rightarrow w_1 \Rightarrow w_2 \Rightarrow \dots \Rightarrow w_n-1 \Rightarrow w_n$
		\item[Notation:] $w'$ yields $w''$ is denotes by $w' \overset{*}{\Rightarrow} w''$.
		\item[Definition:] Let $(V, A, \langle s\rangle , P)$ be a context free grammar. The \underline{language} generated by this grammar is the subset $L$ or $A^*$ defined by $L = \{w \in A^* \mid \langle s\rangle \overset{*}{\Rightarrow} w\}$ \\
		In other words, th language $L$ generated by a context free grammar $(V, A, \langle s\rangle , P)$ consists of the set of all finite strings consisting entirely of terminals that may be obtained from the start symbol $\langle s\rangle $ by applying a finite sequence of production rules of the grammar where the application of one production rule causes \underline{one and only one nonterminal} to be replaced by the string in $V^*$ corresponding of the right hand side of the production rule.
	\end{description}
	
	\subsection{Phrase Structure Grammars}
	\begin{description}
		\item[Definition:] A phrase structure grammar $(V, A, \langle s\rangle , P)$ consists of a finite set $V$, a subset $A$ of $V$, an element $\langle s\rangle $ of $V \backslash A$, and a finite subset $P$ of $(V^* \backslash A^*) \times V^*$ \\
		In a context free grammar, the set of production rules $P \subset (V \backslash A) \times V^*$. \\
		In a phrase structure grammar, $P \subset (V^* \backslash A^*) \times V^*$. In other words, a production rule in a phrase structure grammar $r \rightarrow w$ has a left hand side $n$ that may contain more than one nonterminal. It is required to contain \underline{at least one} nonterminal. \\
		For example, if $A = \{0, 1\}$ and $\langle s\rangle $ is the start symbol in a phrase grammar grammar, 0$\langle s\rangle $0$\langle s\rangle $0 $\rightarrow$ 00010 would be an acceptable production rule in a phrase structure grammar but not in a context free grammar. \\
		The notions $w' \Rightarrow w''$ ($w'$ directly yields $w''$) and $w' \overset{*}{\Rightarrow} w''$ ($w'$ yields $w''$) are defined the same way as for context free grammars except that our production rules may, of course, be more general as we saw in the example above.
		\item[Definition:] Let $(V, A, \langle s\rangle , P)$ be a phrase structure grammar. The language generated by this grammar is the subset $L$ or $A^*$ defined by $L \{w \in A^* \mid \langle s \rangle \overset{*}{\Rightarrow} w \}$
		\item[Remark:] The term phrase structure grammars was introduced by Noam Chomsky.
		\item[Definition:] A language $L$ generated by a context-free grammar is called a \underline{context-free language}.
	\end{description}
	We now want to understand a particularly important subclass of context free languages called regular languages.
	

\end{document}